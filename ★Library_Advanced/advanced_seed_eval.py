# advanced_seed_eval.py
import math
import random
import numpy as np
import torch
import torch.nn as nn

from env_advanced import LibraryShelfEnvAG, DuelingDQN, device

# ğŸ”§ í•™ìŠµí•´ë‘” ìµœì¢… ëª¨ë¸ ê²½ë¡œ (Double + Dueling DQN)
MODEL_PATH = "library_AG_double_dueling.pt"

# ğŸ”§ ì‹¤í—˜ì— ì‚¬ìš©í•  seed ëª©ë¡ (ì›í•˜ëŠ” ëŒ€ë¡œ ë°”ê¿”ë„ ë¨)
SEEDS = [1, 42, 2025]
N_EPISODES = 200  # seedë‹¹ í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜


# ----------------------------------------------------
# 1. ëª¨ë¸ ë¡œë“œ
# ----------------------------------------------------
def load_policy(env):
    state_dim = env.state_dim
    n_actions = 4

    policy = DuelingDQN(state_dim, n_actions).to(device)

    ckpt = torch.load(MODEL_PATH, map_location=device)
    if "state_dict" in ckpt:
        policy.load_state_dict(ckpt["state_dict"])
    else:
        # state_dictë§Œ ì €ì¥í–ˆì„ ë•Œ
        policy.load_state_dict(ckpt)
    policy.eval()

    print(f"ğŸ“¦ Final Model ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
    return policy


# ----------------------------------------------------
# 2. í‰ê°€ í•¨ìˆ˜ (S-start / Random-start ê³µìš©)
# ----------------------------------------------------
def eval_mode(env, policy, num_episodes=200, random_start=True):
    """
    random_start=True  : ë§¤ ì—í”¼ì†Œë“œ ëœë¤ ìœ„ì¹˜ + ëœë¤ íƒ€ê²Ÿ
    random_start=False : í•­ìƒ Sì—ì„œ ì‹œì‘ + ëœë¤ íƒ€ê²Ÿ
    """
    target_keys = env.target_keys

    total_success = 0
    total_steps_success = 0
    total_episodes = num_episodes

    for ep in range(num_episodes):
        ti = random.randint(0, len(target_keys) - 1)
        state = env.reset(target_idx=ti, random_start=random_start)

        done = False
        steps = 0
        info = {}

        while not done and steps < env.max_steps:
            state_t = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)
            with torch.no_grad():
                a = int(policy(state_t).argmax().item())

            state, reward, done, info = env.step(a)
            steps += 1

        reached = info.get("reached_goal", False)

        if reached:
            total_success += 1
            total_steps_success += steps

    success_rate = total_success / total_episodes * 100.0
    avg_steps_success = (
        total_steps_success / total_success if total_success > 0 else 0.0
    )

    return success_rate, avg_steps_success, total_success, total_episodes


# ----------------------------------------------------
# 3. ì´í•­ë¶„í¬ ê¸°ë°˜ 95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
#    (ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜ = seed * N_EPISODES ê¸°ì¤€)
# ----------------------------------------------------
def binom_ci(success, total, alpha=0.05):
    p_hat = success / total
    se = math.sqrt(p_hat * (1 - p_hat) / total)
    z = 1.96  # 95% CI
    low = p_hat - z * se
    high = p_hat + z * se
    return p_hat * 100, low * 100, high * 100


# ----------------------------------------------------
# 4. ë©”ì¸: seedë³„ í‰ê°€ + CI ê³„ì‚°
# ----------------------------------------------------
def main():
    all_s_rates = []
    all_r_rates = []

    total_s_success = 0
    total_s_episodes = 0
    total_r_success = 0
    total_r_episodes = 0

    print("==================================")
    print("ğŸ² Advanced Grid â€“ seedë³„ í‰ê°€ ê²°ê³¼")
    print("==================================")

    for sd in SEEDS:
        # seed ì„¤ì •
        random.seed(sd)
        np.random.seed(sd)
        torch.manual_seed(sd)
        if device.type == "cuda":
            torch.cuda.manual_seed_all(sd)

        env = LibraryShelfEnvAG()
        policy = load_policy(env)

        # S-start
        s_rate, s_avg_steps, s_succ, s_total = eval_mode(
            env, policy, num_episodes=N_EPISODES, random_start=False
        )
        # Random-start
        r_rate, r_avg_steps, r_succ, r_total = eval_mode(
            env, policy, num_episodes=N_EPISODES, random_start=True
        )

        all_s_rates.append(s_rate)
        all_r_rates.append(r_rate)

        total_s_success += s_succ
        total_s_episodes += s_total
        total_r_success += r_succ
        total_r_episodes += r_total

        print(f"\n[Seed {sd}]")
        print(f"  S-start   ì„±ê³µë¥ : {s_rate:5.1f}% | í‰ê·  ìŠ¤í…(ì„±ê³µ ì‹œ): {s_avg_steps:5.1f}")
        print(f"  Random    ì„±ê³µë¥ : {r_rate:5.1f}% | í‰ê·  ìŠ¤í…(ì„±ê³µ ì‹œ): {r_avg_steps:5.1f}")

    # --- ì „ì²´ ì—í”¼ì†Œë“œ ê¸°ì¤€ CI ---
    s_mean, s_low, s_high = binom_ci(total_s_success, total_s_episodes)
    r_mean, r_low, r_high = binom_ci(total_r_success, total_r_episodes)

    print("\n==================================")
    print("ğŸ“Š ì „ì²´ ì—í”¼ì†Œë“œ ê¸°ì¤€ 95% ì‹ ë¢°êµ¬ê°„")
    print("==================================")
    print(
        f"S-start   : {s_mean:5.1f}%  (95% CI: {s_low:5.1f}% ~ {s_high:5.1f}%) "
        f"[ì´ {total_s_success}/{total_s_episodes} ì„±ê³µ]"
    )
    print(
        f"Random    : {r_mean:5.1f}%  (95% CI: {r_low:5.1f}% ~ {r_high:5.1f}%) "
        f"[ì´ {total_r_success}/{total_r_episodes} ì„±ê³µ]"
    )

    # --- ì°¸ê³ ìš©: seed í‰ê·  ê¸°ì¤€ CI (optional) ---
    s_mean_seed = float(np.mean(all_s_rates))
    r_mean_seed = float(np.mean(all_r_rates))
    print("\n(ì°¸ê³ ) seedë³„ ì„±ê³µë¥  í‰ê· ")
    print(f"  S-start  seed í‰ê· : {s_mean_seed:5.2f}%")
    print(f"  Random   seed í‰ê· : {r_mean_seed:5.2f}%")


if __name__ == "__main__":
    main()
