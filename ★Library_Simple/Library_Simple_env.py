# library_env_random_start.py
import random
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import colors
import torch
import torch.nn as nn

plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False


# ==========================================================
# 1. ÎèÑÏÑúÍ¥Ä ÏÑúÍ∞Ä ÌôòÍ≤Ω (ÎûúÎç§ ÏãúÏûëÏ†ê ÏßÄÏõê)
# ==========================================================
class LibraryShelfEnv:
    def __init__(self):
        ascii_map = [
            "#################################################",
            "# S                 B       B                   #",
            "#                                               #",
            "#   AAA   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   BBB   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   CCC     #",
            "#   AAA   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   BBB   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   CCC     #",
            "#   AAA   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   BBB   ‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà   CCC     #",
            "#                                               #",
            "#    B        ‚ñà‚ñà‚ñà‚ñà       B       ‚ñà‚ñà‚ñà‚ñà           #",
            "#             ‚ñà‚ñà‚ñà‚ñà               ‚ñà‚ñà‚ñà‚ñà           #",
            "#                                               #",
            "#                                               #",
            "#################################################",
        ]

        self.height = len(ascii_map)
        self.width = len(ascii_map[0])

        # 0: Î∞îÎã•, 1: Î≤Ω, 2: ÏÑúÍ∞Ä, 3: Î≤§Ïπò
        self.base_map = np.zeros((self.height, self.width), dtype=int)
        self.start = None
        self.targets = {}   # {'A': [...], 'B': [...], 'C': [...]}

        for y, row in enumerate(ascii_map):
            for x, ch in enumerate(row):
                if ch == '#':
                    self.base_map[y, x] = 1

                elif ch == '‚ñà':
                    self.base_map[y, x] = 2  # ÏùºÎ∞ò ÏÑúÍ∞Ä

                elif ch == 'B':
                    # Í∞ÄÏö¥Îç∞ 3Ï§Ñ(y=3~5)Ïùò BÎäî B-ÏÑúÍ∞Ä, ÎÇòÎ®∏ÏßÄÎäî Î≤§Ïπò
                    if 3 <= y <= 5:
                        self.base_map[y, x] = 2
                        self.targets.setdefault('B', []).append((x, y))
                    else:
                        self.base_map[y, x] = 3  # Î≤§Ïπò

                elif ch == 'S':
                    self.start = (x, y)
                    self.base_map[y, x] = 0

                elif ch in ['A', 'C']:
                    self.base_map[y, x] = 2
                    self.targets.setdefault(ch, []).append((x, y))

        self.target_keys = sorted(list(self.targets.keys()))  # ['A','B','C'] Í∏∞ÎåÄ
        print("ÌÉÄÍ≤ü ÏÑúÍ∞Ä Î™©Î°ù:", self.target_keys)

        self.current_target_idx = 0
        self.pos = self.start
        self.goal_poses = []
        self.max_steps = 300
        self.steps = 0

        # üî• ÎûúÎç§ ÏãúÏûëÏ†ê ÌõÑÎ≥¥ (Î∞îÎã• Ïπ∏)
        self.free_cells = [
            (x, y)
            for y in range(self.height)
            for x in range(self.width)
            if self.base_map[y, x] == 0
        ]

    # ---------- Ïú†Ìã∏ ----------
    def _get_access_points(self, target_cells):
        """ÏÑúÍ∞Ä Ï£ºÎ≥ÄÏóêÏÑú Î°úÎ¥áÏù¥ ÏÑ§ Ïàò ÏûàÎäî ÎπàÏπ∏ Ï¢åÌëú"""
        access_points = []
        dirs = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        for tx, ty in target_cells:
            for dx, dy in dirs:
                nx, ny = tx + dx, ty + dy
                if 0 <= nx < self.width and 0 <= ny < self.height:
                    if self.base_map[ny, nx] == 0 and (nx, ny) not in access_points:
                        access_points.append((nx, ny))
        return access_points

    def _nearest_target_cell(self):
        """ÌòÑÏû¨ ÏúÑÏπòÏóêÏÑú Í∞ÄÏû• Í∞ÄÍπåÏö¥ ÏÑúÍ∞Ä Ïπ∏ ÌïòÎÇò ÏÑ†ÌÉù"""
        key = self.target_keys[self.current_target_idx]
        cells = self.targets[key]
        ax, ay = self.pos
        tx, ty = min(cells, key=lambda p: abs(p[0] - ax) + abs(p[1] - ay))
        return tx, ty

    def _get_state(self):
        """[agent_x, agent_y, target_x, target_y] (0~1 Ï†ïÍ∑úÌôî)"""
        ax, ay = self.pos
        tx, ty = self._nearest_target_cell()
        return np.array([
            ax / self.width,
            ay / self.height,
            tx / self.width,
            ty / self.height
        ], dtype=np.float32)

    # ---------- Gym Ïä§ÌÉÄÏùº API ----------
    def reset(self, target_idx=None, random_start=False):
        """
        target_idx: NoneÏù¥Î©¥ A/B/C Ï§ë ÎûúÎç§, ÏïÑÎãàÎ©¥ Ìï¥Îãπ Ïù∏Îç±Ïä§
        random_start: TrueÎ©¥ free_cells Ï§ë ÎûúÎç§ ÏúÑÏπòÏóêÏÑú ÏãúÏûë
        """
        self.steps = 0

        if random_start and self.free_cells:
            self.pos = random.choice(self.free_cells)
        else:
            self.pos = self.start

        if target_idx is None:
            self.current_target_idx = np.random.randint(0, len(self.target_keys))
        else:
            self.current_target_idx = target_idx

        key = self.target_keys[self.current_target_idx]
        self.goal_poses = self._get_access_points(self.targets[key])
        return self._get_state()

    def step(self, action):
        """0:ÏÉÅ, 1:Ìïò, 2:Ï¢å, 3:Ïö∞"""
        self.steps += 1
        x, y = self.pos
        tx, ty = self._nearest_target_cell()
        old_dist = abs(x - tx) + abs(y - ty)

        if action == 0:
            ny, nx = y - 1, x
        elif action == 1:
            ny, nx = y + 1, x
        elif action == 2:
            ny, nx = y, x - 1
        else:
            ny, nx = y, x + 1

        reward = -0.02
        done = False
        hit_wall = False
        reached_goal = False

        # Î≤Ω/ÏÑúÍ∞Ä/Î≤§Ïπò or Îßµ Î∞ñ
        if (nx < 0 or nx >= self.width or
                ny < 0 or ny >= self.height or
                self.base_map[ny, nx] != 0):
            reward -= 0.3
            hit_wall = True
            # ÏúÑÏπòÎäî Í∑∏ÎåÄÎ°ú (Î≤ΩÏóê Î∞ïÌûò)
        else:
            self.pos = (nx, ny)

        # Ïù¥Îèô ÌõÑ Í±∞Î¶¨
        tx, ty = self._nearest_target_cell()
        new_dist = abs(self.pos[0] - tx) + abs(self.pos[1] - ty)
        reward += 0.01 * (old_dist - new_dist)  # Í∞ÄÍπåÏõåÏßÄÎ©¥ +, Î©ÄÏñ¥ÏßÄÎ©¥ -

        if self.pos in self.goal_poses:
            reward += 2.0
            done = True
            reached_goal = True

        if self.steps >= self.max_steps:
            done = True

        info = {"hit_wall": hit_wall, "reached_goal": reached_goal}
        return self._get_state(), reward, done, info


# ==========================================================
# 2. DQN / Dueling DQN ÎÑ§Ìä∏ÏõåÌÅ¨
# ==========================================================
class DQN(nn.Module):
    def __init__(self, state_dim, n_actions, hidden=128):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(state_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, n_actions)
        )

    def forward(self, x):
        return self.net(x)


class DuelingDQN(nn.Module):
    def __init__(self, state_dim, n_actions, hidden=128):
        super().__init__()
        self.feature = nn.Sequential(
            nn.Linear(state_dim, hidden),
            nn.ReLU()
        )
        self.value_stream = nn.Sequential(
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, 1)
        )
        self.adv_stream = nn.Sequential(
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, n_actions)
        )

    def forward(self, x):
        f = self.feature(x)
        value = self.value_stream(f)
        adv = self.adv_stream(f)
        adv_mean = adv.mean(dim=1, keepdim=True)
        return value + adv - adv_mean
