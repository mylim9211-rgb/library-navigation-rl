ğŸ“š Reinforcement Learning for Library Bookshelf Navigation
Simple â†’ Curriculum â†’ Advanced ë‹¨ê³„ë³„ ë‚œì´ë„ í™•ì¥ ê¸°ë°˜ íƒìƒ‰ ì •ì±… í•™ìŠµ
ğŸ“Œ Overview

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë„ì„œê´€ ì„œê°€ í™˜ê²½ì—ì„œ ë¡œë´‡ì´ ëª©í‘œ ìœ„ì¹˜(A~G)ë¥¼ ìŠ¤ìŠ¤ë¡œ íƒìƒ‰í•˜ëŠ” ëŠ¥ë ¥ì„ ê°•í™”í•™ìŠµ(Deep Q-Network, Double/Dueling DQN) ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµÂ·í‰ê°€í•˜ëŠ” ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

í™˜ê²½ì˜ ë‚œì´ë„ë¥¼
Simple â†’ Curriculum â†’ Advanced
ìˆœìœ¼ë¡œ í™•ì¥í•˜ë©°, ì •ì±…ì˜ ì¼ë°˜í™” ì„±ëŠ¥, ì•ˆì •ì„±, seed ì˜ì¡´ì„±, íƒ€ê¹ƒë³„ ì„±ê³µë¥  ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.

ğŸ— í”„ë¡œì íŠ¸ êµ¬ì¡°(Project Structure)
library-navigation-rl/
â”‚
â”œâ”€â”€ â˜…Library_Simple/         # Simple grid í™˜ê²½ + í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ â˜…Library_Curriculum/     # Curriculum í•™ìŠµ í™˜ê²½(Sâ†’Random)
â”œâ”€â”€ â˜…Library_Advanced/       # ìµœì¢… Advanced í™˜ê²½ + Double/Dueling ëª¨ë¸
â”‚
â”œâ”€â”€ README.md                # ì´ ë¬¸ì„œ
â””â”€â”€ .gitignore


ê° í´ë”ëŠ” ë‹¤ìŒ êµ¬ì„±ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:

í´ë”ë³„ ê³µí†µ ì½”ë“œ

env_*.py : Grid í™˜ê²½ ì •ì˜

train_*.py : í•™ìŠµ ì½”ë“œ

test_*.py : í‰ê°€ ì½”ë“œ

*_visual.py : ì‹œê°í™” / ê²½ë¡œ ì¶œë ¥

ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ(Tech Stack)

Python 3.x

PyTorch

NumPy

Matplotlib

Deep Q-Network (DQN)

Double DQN

Dueling Network Architecture

Replay Buffer (Off-policy Learning)

Îµ-greedy Exploration

ğŸ§  í•™ìŠµ ì „ëµ(Learning Strategy)
1) Simple â†’ Curriculum â†’ Advanced ë‹¨ê³„ì  í™•ì¥
ë‹¨ê³„	íŠ¹ì§•
Simple	êµ¬ì¡° ë‹¨ìˆœ / ì¶©ëŒ ê·œì¹™ ìµœì†Œí™” / ê¸°ë³¸ ì´ë™ íŒ¨í„´ í•™ìŠµ
Curriculum	ì¥ì• ë¬¼ + Random Start ë¹„ìœ¨ ì¡°ì ˆë¡œ ì¼ë°˜í™” ê°•í™”
Advanced	ë³µì¡í•œ ì„œê°€(A~G) + ë²½/ë²¤ì¹˜ + ì‹¤ì œ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ë‚œì´ë„
2) Curriculum Learning ê¸°ë²• ì ìš©

í•™ìŠµ ì´ˆë°˜: Random Start 100%

ì¤‘ë°˜: Random ë¹„ìœ¨ ê°ì†Œ â†’ S-start ì§‘ì¤‘ í•™ìŠµ

í›„ë°˜: Generalizationì„ ìœ„í•´ Random Start ë‹¤ì‹œ ì¦ê°€
(0% â†’ 80%)

3) Reward ì„¤ê³„

ê¸°ë³¸ ì´ë™: -0.01 ~ -0.05

ë²½ ì¶©ëŒ: -1.0

ëª©í‘œ ë„ë‹¬: +10 ~ +20

ì§€ë¦„ê¸¸ íƒìƒ‰ ìœ ë„ + ë¶ˆí•„ìš”í•œ ì¶©ëŒ ì–µì œ

ğŸƒâ€â™‚ï¸ ì‹¤í–‰ ë°©ë²• (How to Run)
1) í™˜ê²½ ì„¤ì¹˜
pip install -r requirements.txt

2) Simple í™˜ê²½ í•™ìŠµ
python â˜…Library_Simple/train_simple.py

3) Curriculum í•™ìŠµ
python â˜…Library_Curriculum/train_curriculum.py

4) Advanced í•™ìŠµ
python â˜…Library_Advanced/train_advanced.py

5) í‰ê°€ ì½”ë“œ ì‹¤í–‰
python â˜…Library_Advanced/advanced_eval.py

ğŸ“Š ì£¼ìš” ê²°ê³¼(Results)
Seed ê³ ì • vs Random ë¹„êµ

S-start ì„±ê³µë¥ : ì•½ 83~88%

Random-start ì„±ê³µë¥ : ì•½ 69~75%

95% CI: 69.8% Â± 5.0%

â†’ seed ë³€í™”ì—ë„ ì •ì±…ì´ ì•ˆì •ì ìœ¼ë¡œ ì¼ë°˜í™”ëœ í–‰ë™ íŒ¨í„´ì„ í•™ìŠµí–ˆìŒì„ ì˜ë¯¸.

íƒ€ê¹ƒ(A~G)ë³„ ì„±ê³µë¥ 

Advanced í™˜ê²½ ê¸°ì¤€:

Target	ì„±ê³µë¥ 
A	70%
B	66%
C	70%
D	66%
E	78%
F	90%
G	46%

â†’ G ì„œê°€ëŠ” ì‹¤ì œë¡œë„ êµ¬ì¡°ì ìœ¼ë¡œ ë‚œì´ë„ê°€ ë†’ìŒ â†’ ì—°êµ¬ì ìœ¼ë¡œë„ í¥ë¯¸ë¡œìš´ í¬ì¸íŠ¸.

ğŸ“¸ Sample Path Visualization

(ì´ë¯¸ì§€ íŒŒì¼ ìˆë‹¤ë©´ ë„£ê¸°ğŸ‘‡)

results/
â””â”€â”€ sample_path.png

ğŸ§ª ì‹¤í—˜ ì¬í˜„ì„± (Reproducibility)

ë™ì¼ seed ì„¤ì • ê°€ëŠ¥

Advanced í™˜ê²½ì€ seed 10ê°œ ê¸°ë°˜ CI ê³„ì‚° ì½”ë“œ í¬í•¨

ëª¨ë“  í•™ìŠµ/í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ì •ë¦¬ë¨

ğŸ“ í–¥í›„ ê°œì„  ë°©í–¥(Future Work)

Multi-agent íƒìƒ‰

Actor-Critic ê³„ì—´(PPO, A3C)ë¡œ ì„±ëŠ¥ ë¹„êµ

ë” í˜„ì‹¤ì ì¸ Library Map ì ìš©

LLM ê¸°ë°˜ reward shaping ì ìš© ê°€ëŠ¥ì„± íƒìƒ‰

âœ¨ ë§Œë“ ì´

ì„ì¬ìœ¤ (Sogang Univ. AI SW ëŒ€í•™ì›)
Reinforcement Learning + Library Data Engineering Enthusiast ğŸ˜
