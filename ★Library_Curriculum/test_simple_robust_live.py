# test_simple_robust_live.py
# ==========================================
# ğŸš¨ í° í™”ë©´ ë°©ì§€ ì½”ë“œ
# ==========================================
import matplotlib

try:
    matplotlib.use("TkAgg")
except:
    pass
# ==========================================

import os
import time
import random
import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import colors

# ğŸ’¡ í™˜ê²½ íŒŒì¼ëª… ìˆ˜ì • (env_curriculum)
from env_curriculum import LibraryShelfEnvAG

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ’¡ ìƒˆë¡œ í•™ìŠµí•œ ëª¨ë¸ íŒŒì¼ëª…
MODEL_PATH = "library_simple_robust.pt"


# ----------------------------------------------------
# 1. ëª¨ë¸ êµ¬ì¡° ì •ì˜ (train_simple_robust.pyì™€ ë™ì¼í•´ì•¼ í•¨!)
#    (DuelingDQN_Large ëŒ€ì‹  StandardDQN ì‚¬ìš©)
# ----------------------------------------------------
class StandardDQN(torch.nn.Module):
    def __init__(self, state_dim, n_actions):
        super().__init__()
        self.net = torch.nn.Sequential(
            torch.nn.Linear(state_dim, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, n_actions),
        )

    def forward(self, x):
        return self.net(x)


# ----------------------------------------------------
# 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ë¡œì§ ë‹¨ìˆœí™”)
# ----------------------------------------------------
def load_policy(env):
    if not os.path.exists(MODEL_PATH):
        print(f"ğŸš¨ ëª¨ë¸ íŒŒì¼({MODEL_PATH})ì´ ì—†ìŠµë‹ˆë‹¤. train_simple_robust.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
        return None

    # ëª¨ë¸ ê»ë°ê¸° ìƒì„±
    state_dim = env.state_dim
    n_actions = env.n_actions
    policy = StandardDQN(state_dim, n_actions).to(device)

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    # (ì´ë²ˆ ì½”ë“œëŠ” state_dictë¥¼ ì§ì ‘ ì €ì¥í–ˆìœ¼ë¯€ë¡œ ë°”ë¡œ ë¡œë“œ)
    try:
        policy.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        policy.eval()
        print(f"ğŸ“¦ Robust ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
    except Exception as e:
        print(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    return policy


# ----------------------------------------------------
# 3. ì‹œê°í™” í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ----------------------------------------------------
def render_step(env, traj, ax):
    visual = env.base_map.copy()

    # íƒ€ê²Ÿ ì„œê°€ ê°•ì¡° (4)
    key = env.current_target_key
    for tx, ty in env.targets[key]:
        visual[ty, tx] = 4

    cmap = colors.ListedColormap([
        "#e0e0e0",  # 0 ë°”ë‹¥
        "#000000",  # 1 ë²½/ì¥ì• ë¬¼
        "#8B4513",  # 2 ì¼ë°˜ ì„œê°€
        "#d17f00",  # 3 ë²¤ì¹˜
        "#4B0082",  # 4 íƒ€ê²Ÿ ì„œê°€
    ])

    ax.clear()
    ax.imshow(visual, cmap=cmap, origin="upper", vmin=0, vmax=4)

    if len(traj) > 0:
        xs = [p[0] for p in traj]
        ys = [p[1] for p in traj]

        # ê²½ë¡œì„ 
        ax.plot(xs, ys, "-", linewidth=2, color="cyan", label="Path")
        # ì‹œì‘ì 
        ax.scatter(xs[0], ys[0], c="green", s=80, label="Start", zorder=5)
        # í˜„ì¬ ë¡œë´‡
        ax.scatter(xs[-1], ys[-1], c="blue", s=80, label="Robot", zorder=6)

    ax.set_title(f"Target: {env.current_target_key} | Steps: {env.steps}")
    ax.set_xticks([])
    ax.set_yticks([])
    ax.legend(loc="upper right")


# ----------------------------------------------------
# 4. í…ŒìŠ¤íŠ¸ ë£¨í”„
# ----------------------------------------------------
def test_live(num_episodes=5, random_start=True, sleep_time=0.1):
    env = LibraryShelfEnvAG()
    policy = load_policy(env)
    if policy is None:
        return

    plt.ion()
    fig, ax = plt.subplots(figsize=(10, 5))
    plt.show(block=False)

    success_count = 0
    start_str = "ëœë¤ìœ„ì¹˜" if random_start else "ê³ ì •ìœ„ì¹˜(S)"
    print(f"\nğŸ¬ [Simple Robust] ë¼ì´ë¸Œ í…ŒìŠ¤íŠ¸ ì‹œì‘! ({start_str})")

    for ep in range(num_episodes):
        # íƒ€ê²Ÿ ëœë¤ ì„ íƒ
        target_idx = random.randint(0, len(env.target_keys) - 1)

        # Robust ëª¨ë¸ì€ 50:50ìœ¼ë¡œ í•™ìŠµí–ˆìœ¼ë¯€ë¡œ ë‘˜ ë‹¤ ì˜í•´ì•¼ í•¨
        state = env.reset(target_idx=target_idx, random_start=random_start)

        traj = [env.pos]
        done = False
        info = {}
        steps = 0

        print(f"\nâ–¶ Episode {ep + 1}/{num_episodes} | Target: {env.current_target_key} | Start: {env.pos}")

        while not done and steps < env.max_steps:
            render_step(env, traj, ax)
            fig.canvas.draw()
            fig.canvas.flush_events()
            time.sleep(sleep_time)

            s_t = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)
            with torch.no_grad():
                q = policy(s_t)[0]
            action = int(q.argmax().item())

            state, reward, done, info = env.step(action)
            steps += 1

            if not traj or traj[-1] != env.pos:
                traj.append(env.pos)

        # ë§ˆì§€ë§‰ ì¥ë©´
        render_step(env, traj, ax)
        fig.canvas.draw()
        fig.canvas.flush_events()
        time.sleep(0.5)

        if info.get("reached_goal", False):
            success_count += 1
            print(f"   âœ” ì„±ê³µ! (steps={steps})")
        else:
            print(f"   âœ– ì‹¤íŒ¨.. (steps={steps})")

    plt.ioff()
    plt.show()

    print("\n=====================================")
    print(f"ğŸ¯ ìµœì¢… ê²°ê³¼ ({start_str}): {num_episodes}íŒ ì¤‘ {success_count}íŒ ì„±ê³µ")
    print(f"ğŸ”¥ ì„±ê³µë¥ : {success_count / num_episodes * 100:.1f}%")
    print("=====================================\n")


if __name__ == "__main__":
    # 1. ëœë¤ ì‹œì‘ í…ŒìŠ¤íŠ¸ (ì´ê²Œ ì˜ ë˜ì–´ì•¼ Robust ëª¨ë¸ì„!)
    test_live(num_episodes=5, random_start=True, sleep_time=0.05)

    # 2. ê³ ì • ì‹œì‘ í…ŒìŠ¤íŠ¸ (ì´ê±´ ë‹¹ì—°íˆ ì˜í•´ì•¼ í•¨)
    # test_live(num_episodes=3, random_start=False, sleep_time=0.05)